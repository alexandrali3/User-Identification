{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train/train_feature_21to41.csv', header = 0, encoding = 'utf-8')\n",
    "test_b_df = pd.read_csv('../data/Test-B/test_b_feature_21to41.csv', header = 0, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train_df.drop(['uid','label'],axis=1),label=train_df.label)\n",
    "dtest = lgb.Dataset(test_b_df.drop(['uid'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_series = pd.DataFrame({'uid': test_b_df.uid})\n",
    "def do3(x):\n",
    "    tmp = \"%04d\" % x['uid']\n",
    "    return 'u' + str(tmp)\n",
    "id_series.loc[:, 'uid'] = id_series.apply(do3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {\n",
    "   'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'metric_freq': 100,\n",
    "    'is_training_metric': True,\n",
    "    'min_data_in_leaf': 360,\n",
    "    'num_leaves': 60,\n",
    "    'learning_rate': 0.07,\n",
    "    'is_unbalance': True,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'min_hessian': 0.05,\n",
    "     'verbosity':-1\n",
    "#    'gpu_device_id':2,\n",
    "#     'device':'gpu'\n",
    " #   'lambda_l1': 0.001,\n",
    " #   'skip_drop': 0.95,\n",
    " #   'max_drop' : 10,\n",
    "# 'lambda_l2': 0.005,\n",
    " #'num_threads': 18,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetric(preds,dtrain):\n",
    "    \n",
    "    label = dtrain.get_label()\n",
    "    \n",
    "    \n",
    "    pre = pd.DataFrame({'preds':preds,'label':label})\n",
    "    pre= pre.sort_values(by='preds',ascending=False)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(pre.label,pre.preds)\n",
    "\n",
    "    pre.preds=pre.preds.map(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "    f1 = metrics.f1_score(pre.label,pre.preds)\n",
    "    \n",
    "    \n",
    "    res = 0.6*auc +0.4*f1\n",
    "    \n",
    "    return 'res',res,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tcv_agg's res: 0.741064 + 0.00517984\n",
      "[10]\tcv_agg's res: 0.756045 + 0.00699429\n",
      "[15]\tcv_agg's res: 0.76177 + 0.012525\n",
      "[20]\tcv_agg's res: 0.760009 + 0.0132469\n",
      "[25]\tcv_agg's res: 0.764315 + 0.013599\n",
      "[30]\tcv_agg's res: 0.770501 + 0.013461\n",
      "[35]\tcv_agg's res: 0.773208 + 0.0127656\n",
      "[40]\tcv_agg's res: 0.77833 + 0.0120968\n",
      "[45]\tcv_agg's res: 0.780375 + 0.0121068\n",
      "[50]\tcv_agg's res: 0.78173 + 0.012146\n",
      "[55]\tcv_agg's res: 0.781852 + 0.0115397\n",
      "[60]\tcv_agg's res: 0.78576 + 0.0111986\n",
      "[65]\tcv_agg's res: 0.78746 + 0.0105917\n",
      "[70]\tcv_agg's res: 0.789062 + 0.0112123\n",
      "[75]\tcv_agg's res: 0.78972 + 0.0121855\n",
      "[80]\tcv_agg's res: 0.790743 + 0.0122963\n",
      "[85]\tcv_agg's res: 0.790211 + 0.0118849\n",
      "[90]\tcv_agg's res: 0.791217 + 0.0116651\n",
      "[95]\tcv_agg's res: 0.792203 + 0.0117908\n",
      "[100]\tcv_agg's res: 0.791838 + 0.0130006\n",
      "[105]\tcv_agg's res: 0.794839 + 0.0124376\n",
      "[110]\tcv_agg's res: 0.7948 + 0.0119398\n",
      "[115]\tcv_agg's res: 0.795611 + 0.0123952\n",
      "[120]\tcv_agg's res: 0.796221 + 0.011398\n",
      "[125]\tcv_agg's res: 0.796615 + 0.0110769\n",
      "[130]\tcv_agg's res: 0.797118 + 0.0118183\n",
      "[135]\tcv_agg's res: 0.798238 + 0.0120132\n",
      "[140]\tcv_agg's res: 0.798069 + 0.0130615\n",
      "[145]\tcv_agg's res: 0.797202 + 0.0129512\n",
      "[150]\tcv_agg's res: 0.796596 + 0.0135748\n",
      "[155]\tcv_agg's res: 0.797885 + 0.0129256\n",
      "[160]\tcv_agg's res: 0.797879 + 0.0127981\n",
      "[165]\tcv_agg's res: 0.798651 + 0.0122177\n",
      "[170]\tcv_agg's res: 0.797451 + 0.0136922\n",
      "[175]\tcv_agg's res: 0.798698 + 0.0130561\n",
      "[180]\tcv_agg's res: 0.799267 + 0.0123392\n",
      "[185]\tcv_agg's res: 0.79968 + 0.0133746\n",
      "[190]\tcv_agg's res: 0.799993 + 0.0130839\n",
      "[195]\tcv_agg's res: 0.801352 + 0.0129557\n",
      "[200]\tcv_agg's res: 0.802326 + 0.0114994\n",
      "[205]\tcv_agg's res: 0.80175 + 0.011882\n",
      "[210]\tcv_agg's res: 0.801756 + 0.0118855\n",
      "[215]\tcv_agg's res: 0.802156 + 0.0122006\n",
      "[220]\tcv_agg's res: 0.802167 + 0.0129817\n",
      "[225]\tcv_agg's res: 0.803086 + 0.0122541\n",
      "[230]\tcv_agg's res: 0.805138 + 0.0112688\n",
      "[235]\tcv_agg's res: 0.804192 + 0.0119437\n",
      "[240]\tcv_agg's res: 0.804443 + 0.0125146\n",
      "[245]\tcv_agg's res: 0.804016 + 0.0114825\n",
      "[250]\tcv_agg's res: 0.804638 + 0.0113955\n",
      "[255]\tcv_agg's res: 0.803926 + 0.011191\n",
      "[260]\tcv_agg's res: 0.805784 + 0.0114386\n",
      "[265]\tcv_agg's res: 0.806268 + 0.0119464\n",
      "[270]\tcv_agg's res: 0.806173 + 0.0118553\n",
      "[275]\tcv_agg's res: 0.805218 + 0.0122557\n",
      "[280]\tcv_agg's res: 0.806369 + 0.0116779\n",
      "[285]\tcv_agg's res: 0.806243 + 0.0120659\n",
      "[290]\tcv_agg's res: 0.806982 + 0.0110317\n",
      "[295]\tcv_agg's res: 0.807406 + 0.0105136\n",
      "[300]\tcv_agg's res: 0.807964 + 0.0102946\n",
      "[305]\tcv_agg's res: 0.808275 + 0.0102282\n",
      "[310]\tcv_agg's res: 0.808414 + 0.0115995\n",
      "[315]\tcv_agg's res: 0.808027 + 0.0118404\n",
      "[320]\tcv_agg's res: 0.807804 + 0.0102194\n",
      "[325]\tcv_agg's res: 0.807586 + 0.0115123\n",
      "[330]\tcv_agg's res: 0.807557 + 0.0115918\n",
      "[335]\tcv_agg's res: 0.807542 + 0.0102052\n",
      "[340]\tcv_agg's res: 0.807169 + 0.00986899\n",
      "[345]\tcv_agg's res: 0.806662 + 0.00974469\n",
      "[350]\tcv_agg's res: 0.806784 + 0.00963792\n",
      "[355]\tcv_agg's res: 0.805583 + 0.0100681\n",
      "[360]\tcv_agg's res: 0.806487 + 0.0112751\n",
      "[365]\tcv_agg's res: 0.807253 + 0.0103566\n",
      "[370]\tcv_agg's res: 0.806725 + 0.0106904\n",
      "[375]\tcv_agg's res: 0.806243 + 0.0113403\n",
      "[380]\tcv_agg's res: 0.806988 + 0.0113068\n",
      "[385]\tcv_agg's res: 0.808057 + 0.0124514\n",
      "[390]\tcv_agg's res: 0.807984 + 0.0116459\n",
      "[395]\tcv_agg's res: 0.809387 + 0.0106645\n",
      "[400]\tcv_agg's res: 0.807896 + 0.0123393\n",
      "[405]\tcv_agg's res: 0.80821 + 0.0123529\n",
      "[410]\tcv_agg's res: 0.808295 + 0.0122414\n",
      "[415]\tcv_agg's res: 0.807476 + 0.0112026\n",
      "[420]\tcv_agg's res: 0.806966 + 0.0123565\n",
      "[425]\tcv_agg's res: 0.807211 + 0.0110813\n",
      "[430]\tcv_agg's res: 0.807352 + 0.0107106\n",
      "[435]\tcv_agg's res: 0.807028 + 0.0111278\n",
      "[440]\tcv_agg's res: 0.80645 + 0.010728\n",
      "[445]\tcv_agg's res: 0.806478 + 0.0113872\n",
      "[450]\tcv_agg's res: 0.805445 + 0.0100562\n",
      "[455]\tcv_agg's res: 0.804653 + 0.0102868\n",
      "[460]\tcv_agg's res: 0.805416 + 0.00973155\n",
      "[465]\tcv_agg's res: 0.804622 + 0.00897017\n",
      "[470]\tcv_agg's res: 0.804679 + 0.00940394\n",
      "[475]\tcv_agg's res: 0.805157 + 0.00998085\n",
      "[480]\tcv_agg's res: 0.804594 + 0.0106587\n",
      "[485]\tcv_agg's res: 0.805273 + 0.0103737\n",
      "[490]\tcv_agg's res: 0.80429 + 0.0108434\n",
      "[495]\tcv_agg's res: 0.804658 + 0.0110849\n",
      "[500]\tcv_agg's res: 0.80521 + 0.0110381\n"
     ]
    }
   ],
   "source": [
    "cv_results = lgb.cv(lgb_params,dtrain,feval=evalMetric,early_stopping_rounds=150,verbose_eval=5,num_boost_round=500,nfold=3,metrics=['evalMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093868157999052\n"
     ]
    }
   ],
   "source": [
    "res_mean = pd.Series(cv_results['res-mean']).max()\n",
    "print(res_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's res: 0.766355\n",
      "[10]\ttraining's res: 0.784702\n",
      "[15]\ttraining's res: 0.787777\n",
      "[20]\ttraining's res: 0.785147\n",
      "[25]\ttraining's res: 0.792233\n",
      "[30]\ttraining's res: 0.799752\n",
      "[35]\ttraining's res: 0.80836\n",
      "[40]\ttraining's res: 0.813431\n",
      "[45]\ttraining's res: 0.818275\n",
      "[50]\ttraining's res: 0.822123\n",
      "[55]\ttraining's res: 0.825812\n",
      "[60]\ttraining's res: 0.828663\n",
      "[65]\ttraining's res: 0.832476\n",
      "[70]\ttraining's res: 0.835648\n",
      "[75]\ttraining's res: 0.838653\n",
      "[80]\ttraining's res: 0.841609\n",
      "[85]\ttraining's res: 0.844488\n",
      "[90]\ttraining's res: 0.846826\n",
      "[95]\ttraining's res: 0.849786\n",
      "[100]\ttraining's res: 0.853324\n",
      "[105]\ttraining's res: 0.855972\n",
      "[110]\ttraining's res: 0.858206\n",
      "[115]\ttraining's res: 0.861998\n",
      "[120]\ttraining's res: 0.864252\n",
      "[125]\ttraining's res: 0.867077\n",
      "[130]\ttraining's res: 0.868807\n",
      "[135]\ttraining's res: 0.871336\n",
      "[140]\ttraining's res: 0.874778\n",
      "[145]\ttraining's res: 0.878155\n",
      "[150]\ttraining's res: 0.879234\n",
      "[155]\ttraining's res: 0.881702\n",
      "[160]\ttraining's res: 0.8833\n",
      "[165]\ttraining's res: 0.885504\n",
      "[170]\ttraining's res: 0.888196\n",
      "[175]\ttraining's res: 0.890523\n",
      "[180]\ttraining's res: 0.892759\n",
      "[185]\ttraining's res: 0.893804\n",
      "[190]\ttraining's res: 0.8956\n",
      "[195]\ttraining's res: 0.89736\n",
      "[200]\ttraining's res: 0.900188\n",
      "[205]\ttraining's res: 0.90202\n",
      "[210]\ttraining's res: 0.904115\n",
      "[215]\ttraining's res: 0.905274\n",
      "[220]\ttraining's res: 0.906552\n",
      "[225]\ttraining's res: 0.908635\n",
      "[230]\ttraining's res: 0.90998\n",
      "[235]\ttraining's res: 0.911385\n",
      "[240]\ttraining's res: 0.9126\n",
      "[245]\ttraining's res: 0.914564\n",
      "[250]\ttraining's res: 0.915712\n",
      "[255]\ttraining's res: 0.915731\n",
      "[260]\ttraining's res: 0.916697\n",
      "[265]\ttraining's res: 0.918093\n",
      "[270]\ttraining's res: 0.919469\n",
      "[275]\ttraining's res: 0.920245\n",
      "[280]\ttraining's res: 0.92144\n",
      "[285]\ttraining's res: 0.922876\n",
      "[290]\ttraining's res: 0.92447\n",
      "[295]\ttraining's res: 0.925487\n",
      "[300]\ttraining's res: 0.926869\n",
      "[305]\ttraining's res: 0.928214\n",
      "[310]\ttraining's res: 0.929961\n",
      "[315]\ttraining's res: 0.930851\n",
      "[320]\ttraining's res: 0.931747\n",
      "[325]\ttraining's res: 0.932965\n",
      "[330]\ttraining's res: 0.933619\n",
      "[335]\ttraining's res: 0.934589\n",
      "[340]\ttraining's res: 0.936083\n",
      "[345]\ttraining's res: 0.936715\n",
      "[350]\ttraining's res: 0.936703\n",
      "[355]\ttraining's res: 0.937202\n",
      "[360]\ttraining's res: 0.938296\n",
      "[365]\ttraining's res: 0.939397\n",
      "[370]\ttraining's res: 0.940529\n",
      "[375]\ttraining's res: 0.94147\n",
      "[380]\ttraining's res: 0.942037\n",
      "[385]\ttraining's res: 0.943003\n",
      "[390]\ttraining's res: 0.943248\n",
      "[395]\ttraining's res: 0.944593\n",
      "[400]\ttraining's res: 0.945043\n",
      "[405]\ttraining's res: 0.945338\n",
      "[410]\ttraining's res: 0.946474\n"
     ]
    }
   ],
   "source": [
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=410,valid_sets=[dtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_b_df.drop(['uid'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'uid':id_series['uid'],'label':pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72698149 0.81999519 0.01719991 ... 0.70888424 0.39057942 0.52914757]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=res.sort_values(by='label',ascending=False)\n",
    "res.label=res.label.map(lambda x: 1 if x>=0.5 else 0)\n",
    "# res.label = res.label.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label    uid\n",
      "1749      1  u8749\n",
      "2227      1  u9227\n",
      "2406      1  u9406\n",
      "628       1  u7628\n",
      "2233      1  u9233\n",
      "554       1  u7554\n",
      "1760      1  u8760\n",
      "1076      1  u8076\n",
      "1133      1  u8133\n",
      "406       1  u7406\n",
      "1136      1  u8136\n",
      "893       1  u7893\n",
      "606       1  u7606\n",
      "693       1  u7693\n",
      "639       1  u7639\n",
      "1477      1  u8477\n",
      "337       1  u7337\n",
      "2986      1  u9986\n",
      "886       1  u7886\n",
      "1603      1  u8603\n",
      "1135      1  u8135\n",
      "609       1  u7609\n",
      "1326      1  u8326\n",
      "1250      1  u8250\n",
      "1098      1  u8098\n",
      "353       1  u7353\n",
      "1530      1  u8530\n",
      "1044      1  u8044\n",
      "2110      1  u9110\n",
      "547       1  u7547\n",
      "...     ...    ...\n",
      "41        0  u7041\n",
      "2475      0  u9475\n",
      "782       0  u7782\n",
      "1404      0  u8404\n",
      "2247      0  u9247\n",
      "1696      0  u8696\n",
      "536       0  u7536\n",
      "505       0  u7505\n",
      "1037      0  u8037\n",
      "1321      0  u8321\n",
      "869       0  u7869\n",
      "889       0  u7889\n",
      "2430      0  u9430\n",
      "2023      0  u9023\n",
      "154       0  u7154\n",
      "2917      0  u9917\n",
      "1324      0  u8324\n",
      "446       0  u7446\n",
      "1534      0  u8534\n",
      "1081      0  u8081\n",
      "2809      0  u9809\n",
      "734       0  u7734\n",
      "105       0  u7105\n",
      "203       0  u7203\n",
      "1476      0  u8476\n",
      "1514      0  u8514\n",
      "884       0  u7884\n",
      "2892      0  u9892\n",
      "825       0  u7825\n",
      "1154      0  u8154\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../result/lgb-baseline-10.csv',index=False,header=False,sep=',',columns=['uid','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train/train_feature_21to33.csv', header = 0, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_df = pd.read_csv('../data/Test-A/test_a_feature_21to33.csv', header = 0, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.set_index(u'uid')\n",
    "test_a_df = test_a_df.set_index(u'uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train_df.shape[0]\n",
    "ntest = test_a_df.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 4 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds = NFOLDS, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clf.fit(x, y)\n",
    "    \n",
    "    def feature_importances(self, x, y):\n",
    "        print (self.clf.fit(x, y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_time_stamp():\n",
    "    now = int(time.time())\n",
    "    return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0,\n",
    "    'loss': 'deviance'\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 5 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4999L, 48L), (2000L, 48L), (4999L,))\n"
     ]
    }
   ],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train_df['label'].ravel()\n",
    "train_noy = train_df.drop(['label'], axis=1)\n",
    "x_train = train_noy.values # Creates an array of the train data\n",
    "x_test = test_a_df.values # Creats an array of the test data\n",
    "print (x_train.shape, x_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_precision(preds, dtrain):\n",
    "    label = dtrain['label']\n",
    "    \n",
    "    pre = pd.DataFrame({'preds':preds,'label':label})\n",
    "    print(pre)\n",
    "    pre= pre.sort_values(by='preds',ascending=False)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(pre.label,pre.preds)\n",
    "\n",
    "    pre.preds=pre.preds.map(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "    f1 = metrics.f1_score(pre.label,pre.preds)\n",
    "    \n",
    "    \n",
    "    res = 0.6*auc +0.4*f1\n",
    "    \n",
    "    return 'res',res,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        # print(x_tr, y_tr, x_te)\n",
    "\n",
    "        time_before_train = get_time_stamp()\n",
    "        clf.train(x_tr, y_tr)\n",
    "        print(\"time for training:\")\n",
    "        print(get_time_stamp() - time_before_train)\n",
    "\n",
    "        time_before_predict = get_time_stamp()\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "        print(\"time for predicting\")\n",
    "        print(get_time_stamp() - time_before_predict)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    pd.Series(oof_train).to_csv('../data/oof_train.csv', header = None)\n",
    "    print(cal_precision(pd.Series(oof_train), dtrain))\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof2(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    \n",
    "    time_before_train = get_time_stamp()\n",
    "    clf.train(x_train, y_train)\n",
    "    print(\"time for training:\")\n",
    "    print(get_time_stamp() - time_before_train)\n",
    "    \n",
    "    time_before_predict = get_time_stamp()\n",
    "    oof_train = clf.predict(x_train)\n",
    "    oof_test = clf.predict(x_test)\n",
    "    print(\"time for predicting\")\n",
    "    print(get_time_stamp() - time_before_predict)\n",
    "    \n",
    "    # oof_train = oof_train.reshape(-1, 1)\n",
    "    oof_test = oof_test.reshape(-1, 1)\n",
    "    # print(cal_precision(oof_train, y_train.reshape(-1, 1)))\n",
    "    return oof_train.reshape(-1, 1), oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for training:\n",
      "1\n",
      "time for predicting\n",
      "1\n",
      "Training is complete\n",
      "time for training:\n",
      "8\n",
      "time for predicting\n",
      "1\n",
      "Training is complete\n",
      "time for training:\n",
      "13\n",
      "time for predicting\n",
      "0\n",
      "Training is complete\n",
      "Training is complete!!!\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof2(et, x_train, y_train, x_test) # Extra Trees\n",
    "print(\"Training is complete\")\n",
    "\n",
    "# rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "# print(\"Training is complete\")\n",
    "\n",
    "ada_oof_train, ada_oof_test = get_oof2(ada, x_train, y_train, x_test) # AdaBoost \n",
    "print(\"Training is complete\")\n",
    "\n",
    "gb_oof_train, gb_oof_test = get_oof2(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "print(\"Training is complete\")\n",
    "\n",
    "# svc_oof_train, svc_oof_test = get_oof2(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "# print(\"Training is complete\")\n",
    "\n",
    "print(\"Training is complete!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, ada_oof_train, gb_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, ada_oof_test, gb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)\n",
    "predictions = gbm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_series = pd.DataFrame({'uid': test_a_df.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do3(x):\n",
    "    tmp = \"%04d\" % x['uid']\n",
    "    return 'u' + str(tmp)\n",
    "id_series.loc[:, 'uid'] = id_series.apply(do3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       u5000\n",
      "1       u5001\n",
      "2       u5002\n",
      "3       u5003\n",
      "4       u5004\n",
      "5       u5005\n",
      "6       u5006\n",
      "7       u5007\n",
      "8       u5008\n",
      "9       u5009\n",
      "10      u5010\n",
      "11      u5011\n",
      "12      u5012\n",
      "13      u5013\n",
      "14      u5014\n",
      "15      u5015\n",
      "16      u5016\n",
      "17      u5017\n",
      "18      u5018\n",
      "19      u5019\n",
      "20      u5020\n",
      "21      u5021\n",
      "22      u5022\n",
      "23      u5023\n",
      "24      u5024\n",
      "25      u5025\n",
      "26      u5026\n",
      "27      u5027\n",
      "28      u5028\n",
      "29      u5029\n",
      "        ...  \n",
      "1970    u6970\n",
      "1971    u6971\n",
      "1972    u6972\n",
      "1973    u6973\n",
      "1974    u6974\n",
      "1975    u6975\n",
      "1976    u6976\n",
      "1977    u6977\n",
      "1978    u6978\n",
      "1979    u6979\n",
      "1980    u6980\n",
      "1981    u6981\n",
      "1982    u6982\n",
      "1983    u6983\n",
      "1984    u6984\n",
      "1985    u6985\n",
      "1986    u6986\n",
      "1987    u6987\n",
      "1988    u6988\n",
      "1989    u6989\n",
      "1990    u6990\n",
      "1991    u6991\n",
      "1992    u6992\n",
      "1993    u6993\n",
      "1994    u6994\n",
      "1995    u6995\n",
      "1996    u6996\n",
      "1997    u6997\n",
      "1998    u6998\n",
      "1999    u6999\n",
      "Name: uid, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(id_series['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame({'uid': id_series['uid'], 'label': predictions}, columns = ['uid', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ans.sort_values(by='label', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('../result/ans_4_df.csv', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
